{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Creating extensions using numpy and scipy\n",
    "=========================================\n",
    "**Author**: `Adam Paszke <https://github.com/apaszke>`_\n",
    "\n",
    "In this tutorial, we shall go through two tasks:\n",
    "\n",
    "1. Create a neural network layer with no parameters.\n",
    "\n",
    "    -  This calls into **numpy** as part of it’s implementation\n",
    "\n",
    "2. Create a neural network layer that has learnable weights\n",
    "\n",
    "    -  This calls into **SciPy** as part of it’s implementation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Function\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter-less example\n",
    "----------------------\n",
    "\n",
    "This layer doesn’t particularly do anything useful or mathematically\n",
    "correct.\n",
    "\n",
    "It is aptly named BadFFTFunction\n",
    "\n",
    "**Layer Implementation**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.fft import rfft2, irfft2\n",
    "\n",
    "\n",
    "class BadFFTFunction(Function):\n",
    "\n",
    "    def forward(self, input):\n",
    "        numpy_input = input.numpy()\n",
    "        result = abs(rfft2(numpy_input))\n",
    "        return torch.FloatTensor(result)\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        numpy_go = grad_output.numpy()\n",
    "        result = irfft2(numpy_go)\n",
    "        return torch.FloatTensor(result)\n",
    "\n",
    "# since this layer does not have any parameters, we can\n",
    "# simply declare this as a function, rather than as an nn.Module class\n",
    "\n",
    "\n",
    "def incorrect_fft(input):\n",
    "    return BadFFTFunction()(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example usage of the created layer:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  6.1829  11.9744   9.8176  10.8280   0.5950\n",
      "  4.8383   5.6456  10.3967   2.3743   1.9450\n",
      "  6.2943   6.1773   5.7614   6.7952   2.6731\n",
      "  7.7006   3.2616  13.8528   7.4106  11.7680\n",
      "  1.0098  19.0406   5.7653   0.6019   2.0653\n",
      "  7.7006   2.5807   8.4803  11.8092  11.7680\n",
      "  6.2943   3.4272   8.0550   8.7194   2.6731\n",
      "  4.8383   6.6792   9.6886   8.8778   1.9450\n",
      "[torch.FloatTensor of size 8x5]\n",
      "\n",
      "Variable containing:\n",
      " 0.0523  0.0843 -0.0460  0.0436 -0.0750  0.0436 -0.0460  0.0843\n",
      " 0.0413 -0.0303 -0.0125  0.2037 -0.0425 -0.0145  0.0988  0.0422\n",
      "-0.0930 -0.1588 -0.0845  0.1245  0.2047  0.1530 -0.0745 -0.0850\n",
      " 0.2796 -0.1453 -0.2112 -0.1489  0.0792  0.0275 -0.0544 -0.0301\n",
      " 0.0008  0.0009  0.0486 -0.1282 -0.1561 -0.1282  0.0486  0.0009\n",
      " 0.2796 -0.0301 -0.0544  0.0275  0.0792 -0.1489 -0.2112 -0.1453\n",
      "-0.0930 -0.0850 -0.0745  0.1530  0.2047  0.1245 -0.0845 -0.1588\n",
      " 0.0413  0.0422  0.0988 -0.0145 -0.0425  0.2037 -0.0125 -0.0303\n",
      "[torch.FloatTensor of size 8x8]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input = Variable(torch.randn(8, 8), requires_grad=True)\n",
    "result = incorrect_fft(input)\n",
    "print(result.data)\n",
    "result.backward(torch.randn(result.size()))\n",
    "print(input.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parametrized example\n",
    "--------------------\n",
    "\n",
    "This implements a layer with learnable weights.\n",
    "\n",
    "It implements the Cross-correlation with a learnable kernel.\n",
    "\n",
    "In deep learning literature, it’s confusingly referred to as\n",
    "Convolution.\n",
    "\n",
    "The backward computes the gradients wrt the input and gradients wrt the\n",
    "filter.\n",
    "\n",
    "**Implementation:**\n",
    "\n",
    "*Please Note that the implementation serves as an illustration, and we\n",
    "did not verify it’s correctness*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import convolve2d, correlate2d\n",
    "from torch.nn.modules.module import Module\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "\n",
    "class ScipyConv2dFunction(Function):\n",
    "\n",
    "    def forward(self, input, filter):\n",
    "        result = correlate2d(input.numpy(), filter.numpy(), mode='valid')\n",
    "        self.save_for_backward(input, filter)\n",
    "        return torch.FloatTensor(result)\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        input, filter = self.saved_tensors\n",
    "        grad_input = convolve2d(grad_output.numpy(), filter.t().numpy(), mode='full')\n",
    "        grad_filter = convolve2d(input.numpy(), grad_output.numpy(), mode='valid')\n",
    "        return torch.FloatTensor(grad_input), torch.FloatTensor(grad_filter)\n",
    "\n",
    "\n",
    "class ScipyConv2d(Module):\n",
    "\n",
    "    def __init__(self, kh, kw):\n",
    "        super(ScipyConv2d, self).__init__()\n",
    "        self.filter = Parameter(torch.randn(kh, kw))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return ScipyConv2dFunction()(input, self.filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example usage:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "-2.6030 -0.3843  0.5587\n",
      " 0.2654  1.3264 -2.1400\n",
      " 1.9451  0.0599 -0.2262\n",
      "[torch.FloatTensor of size 3x3]\n",
      "]\n",
      "Variable containing:\n",
      "  3.5203  -1.3729   3.1299   3.4696  -0.2412   3.3267   4.0775 -11.2150\n",
      "  4.1776  -2.4674   2.0483   0.0354   1.3668   6.8117  -4.1741   1.5168\n",
      " -5.6433  -2.6592   2.3315  -0.3444  -2.2906  -2.6987  -4.0895   2.3890\n",
      " -5.0757   1.4878   3.6190  -3.1724   2.4341   1.4937  -3.1806  -8.2635\n",
      " -1.5748   1.8645  -2.3110  -1.3063  -2.5158   5.8617  -2.5098   1.9802\n",
      "  2.2826   4.3955   0.5357   1.6774   3.4699  -6.2313  -5.0198  10.3553\n",
      "  4.9095   0.0631  -5.9529   7.2286   5.4995  -6.0974   0.7383   2.1105\n",
      " -4.5536  -6.7273   9.5790  -2.9598  -6.3236   1.5818   5.8783  -2.4652\n",
      "[torch.FloatTensor of size 8x8]\n",
      "\n",
      "Variable containing:\n",
      "\n",
      "Columns 0 to 7 \n",
      " -1.1491   3.1455  -6.2042  -2.1850   4.7667   0.2857   3.5723   3.6078\n",
      "  3.7457   1.8007  -6.4104   4.5249  -0.3350  -0.4320   7.2227  -3.8357\n",
      " -5.0664   0.4539   8.9772  -4.8787  -1.3874  -1.8264  -4.6696   1.0171\n",
      "  0.3112  11.1160  -5.3831  -4.3919   2.5912   1.6789   1.9282  -1.4375\n",
      "  0.9139  -4.5577  -3.3064   3.1146   0.9853   3.2194   0.8069  -1.1957\n",
      "  0.0399  -2.6764   5.3072   2.5339  -2.3519  -0.3940  -2.5991   2.9131\n",
      "  5.7876  -4.6305   3.9257   0.0375  -6.3656   7.2158   1.3070  -6.1409\n",
      " -0.8435  -3.5963  -2.5269   0.8605  -0.7539   0.9189  -4.3355  -8.4698\n",
      " -1.4221   5.6098  -1.7907   4.3783   1.1692  -2.8106   5.8626   4.8998\n",
      "  0.3311  -0.8747  -1.1523  -2.1827   0.9591  -2.0714   0.4153  -3.4032\n",
      "\n",
      "Columns 8 to 9 \n",
      " -2.8489  -2.8322\n",
      " -6.2033   1.0527\n",
      "  5.6814  -1.0330\n",
      " -3.0502   3.2990\n",
      "  2.6834  -2.2962\n",
      " -0.5884  -0.2584\n",
      "  2.0919   2.3662\n",
      "  4.4241   2.0606\n",
      " -0.6167  -0.1773\n",
      " -2.6428  -0.2353\n",
      "[torch.FloatTensor of size 10x10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "module = ScipyConv2d(3, 3)\n",
    "print(list(module.parameters()))\n",
    "input = Variable(torch.randn(10, 10), requires_grad=True)\n",
    "output = module(input)\n",
    "print(output)\n",
    "output.backward(torch.randn(8, 8))\n",
    "print(input.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
