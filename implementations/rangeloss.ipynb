{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = np.array([\n",
    "    [1, 1, 1], \n",
    "    [1, 1, 2], \n",
    "    [2, 2, 3], \n",
    "    [2, 2, 2], \n",
    "    [3, 4, 2], \n",
    "    [4, 4, 5]\n",
    "])\n",
    "labels_test= np.array([\n",
    "    0,\n",
    "    0,\n",
    "    1,\n",
    "    1,\n",
    "    2,\n",
    "    2\n",
    "])\n",
    "m_test = 0.2\n",
    "w_test = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rangeloss(logits, labels):\n",
    "    \"\"\"\n",
    "    Inputs: \n",
    "        x - feature set from last fully connected layer\n",
    "        labels - the class labels (identities for each feature vector)\n",
    "        m - margin\n",
    "        w - lambda, or the balance between intra / inter class loss\n",
    "        \n",
    "    Output:\n",
    "        Loss, gradients (with respect to x)\n",
    "    \"\"\"\n",
    "    k = 2\n",
    "    m = 0.4\n",
    "    w = 0.5\n",
    "    alpha = 0.5\n",
    "    beta = 1.0 - alpha\n",
    "    \n",
    "    inter_class_grad = np.zeros(logits.shape[0])\n",
    "    intra_class_grad = np.zeros(logits.shape[0])\n",
    "    \n",
    "    data_by_class = defaultdict(lambda: [])\n",
    "    average_by_class = defaultdict(lambda: 0)\n",
    "    k_largest_dist = defaultdict(lambda: [])\n",
    "    harmonic_mean_by_class = defaultdict(lambda: 0)\n",
    "    \n",
    "    # group data by class\n",
    "    for feature, label in zip(x, labels):\n",
    "        data_by_class[label].append(feature)\n",
    "        \n",
    "    #compute mean\n",
    "    keys = data_by_class.keys()\n",
    "    for key in keys:\n",
    "        average_by_class[key] = np.sum(data_by_class[key], axis=0)/len(data_by_class[key])\n",
    "    \n",
    "    # compute k largest Distances (euclidean) among\n",
    "    # features xi of class i\n",
    "    for key in keys:\n",
    "        distances = np.array([np.linalg.norm(np.array(a)-np.array(b)) for a in data_by_class[key] for b in data_by_class[key]])\n",
    "        distances.sort()\n",
    "        distances = distances[::-1]\n",
    "        for i in range(k):\n",
    "            k_largest_dist[key].append(distances[i])\n",
    "            \n",
    "    # compute the harmonic range\n",
    "    for key in keys:\n",
    "        harmonic_mean_by_class[key] = np.sum([1.0 / k_largest_dist[key][i] for i in range(k)])\n",
    "        \n",
    "    # compute total intra class loss\n",
    "    intra_class_loss = k * np.sum([1.0 / harmonic_mean_by_class[key] for key in keys])\n",
    "    \n",
    "    # compute intra class gradient???\n",
    "    \n",
    "    \n",
    "    # compute shortest distances between all feature centers\n",
    "    inter_class_dist = np.array([np.linalg.norm(np.array(average_by_class[key1])-np.array(average_by_class[key2])) for key1 in keys for key2 in keys if key1 != key2])\n",
    "    inter_class_dist.sort()\n",
    "    \n",
    "    #compute inter-class loss\n",
    "    inter_class_loss = m - inter_class_dist[0]\n",
    "    if inter_class_loss < 0:\n",
    "        inter_class_loss = 0\n",
    "    \n",
    "    # compute the inter-class gradient???\n",
    "    if inter_class_loss > 0:\n",
    "        inter_class_grad = np.zeros(x.shape[0])\n",
    "    else:\n",
    "        inter_class_grad = np.zeros(x.shape[0])\n",
    "    \n",
    "    # combine the loss and gradients\n",
    "    loss = alpha * inter_class_loss + beta * intra_class_loss\n",
    "    gradients = alpha * inter_class_grad + beta * intra_class_grad\n",
    "    \n",
    "    #print(\"inter-class loss: \", inter_class_loss)\n",
    "    #print(\"intra-class loss: \", intra_class_loss)\n",
    "    #print(\"inter-class gradients: \", inter_class_grad)\n",
    "    #print(\"intra-class gradients: \", intra_class_grad)\n",
    "    \n",
    "    #print(\"data by class: \", data_by_class)\n",
    "    #print(\"averages by class: \", average_by_class)\n",
    "    #print(\"k largest distances per class: \", k_largest_dist)\n",
    "    #print(\"harmonic means by class: \", harmonic_mean_by_class)\n",
    "    #print(\"inter-class distances: \", inter_class_dist)\n",
    "    \n",
    "    return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.58113883008\n"
     ]
    }
   ],
   "source": [
    "result_test = rangeloss(X_test, labels_test, m_test, w_test)\n",
    "print(result_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (facialRecognition)",
   "language": "python",
   "name": "facialrecognition"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
